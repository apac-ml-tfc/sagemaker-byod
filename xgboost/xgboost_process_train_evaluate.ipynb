{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker with XGBoost and Hyperparameter Tuning\n",
    "_**Supervised Learning with Gradient Boosted Trees: A Binary Prediction Problem With Unbalanced Classes**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prepare our Environment\n",
    "\n",
    "We'll need to:\n",
    "\n",
    "- **import** some useful libraries (as in any Python notebook)\n",
    "- **configure** the S3 bucket and folder where data should be stored (to keep our environment tidy)\n",
    "- **connect** to AWS in general (with [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)) and SageMaker in particular (with the [sagemaker SDK](https://sagemaker.readthedocs.io/en/stable/)), to use the cloud services\n",
    "\n",
    "While `boto3` is the general AWS SDK for Python, `sagemaker` provides some powerful, higher-level interfaces designed specifically for ML workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up SageMaker parameters\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "bucket_prefix = \"xgboost-example\"  # Location in the bucket to store our files\n",
    "sm_session = sagemaker.Session()\n",
    "sm_client = boto_session.client(\"sagemaker\")\n",
    "sm_role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=#\"<dataset path local or from s3>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label=#'<write your target label name here>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload CSV files to S3 for SageMaker processing and training\n",
    "rawdata_uri = sm_session.upload_data(\n",
    "    path=dataset_path,\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=bucket_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.xlarge',\n",
    "                                     instance_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from datetime import datetime\n",
    "\n",
    "job_name='xgboost-processing-'+datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "output_path_train='s3://'+bucket_name+'/'+job_name+'/processing/output/train/'\n",
    "output_path_val='s3://'+bucket_name+'/'+job_name+'/processing/output/validation/'\n",
    "output_path_test='s3://'+bucket_name+'/'+job_name+'/processing/output/test/'\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code='scripts/preprocess.py',\n",
    "    job_name=job_name, \n",
    "    #arguments = ['arg1', 'arg2'],\n",
    "    inputs=[ProcessingInput(\n",
    "        source=dataset_path,\n",
    "        #source = 's3_path_to_data'\n",
    "        destination='/opt/ml/processing/input')],\n",
    "    outputs=[ProcessingOutput(source='/opt/ml/processing/output/train', destination = output_path_train),\n",
    "        ProcessingOutput(source='/opt/ml/processing/output/validation', destination = output_path_val),\n",
    "        ProcessingOutput(source='/opt/ml/processing/output/test', destination = output_path_test)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sagemaker Built-in XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using SageMaker's built-in XGBoost Algorithm: Benefiting from performance-optimized, pre-implemented functionality like multi-instance parallelization, and support for multiple input formats.\n",
    "\n",
    "In general to use the pre-built algorithms, we'll need to:\n",
    "\n",
    "    Refer to the Common Parameters docs to see the high-level configuration and what features each algorithm has\n",
    "    Refer to the algorithm docs to understand the detail of the data formats and (hyper)-parameters it supports\n",
    "\n",
    "From these docs, we'll understand what data format we need to upload to S3 (next), and how to get the container image URI of the algorithm... which is listed on the Common Parameters page but can also be extracted through the SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify container\n",
    "training_image = sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"1.0-1\")\n",
    "\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model on SageMaker follows the usual steps with other ML libraries (e.g. SciKit-Learn):\n",
    "\n",
    "    Initiate a session (we did this up top).\n",
    "    Instantiate an estimator object for our algorithm (XGBoost).\n",
    "    Define its hyperparameters.\n",
    "    Start the training job.\n",
    "\n",
    "A small competition!\n",
    "\n",
    "SageMaker's XGBoost includes 38 parameters. You can find more information about them here. For simplicity, we choose to experiment only with a few of them.\n",
    "\n",
    "...and finally, actually create the training job using the high-level Estimator API.\n",
    "\n",
    "The Estimator class provides a familiar, scikit-learn-like API for fit()ting models to data, deploy()ing models to real-time endpoints, or running batch inference jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data input channels for the training job:\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(output_path_train, content_type=\"csv\")\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(output_path_val, content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an XGBoost estimator object\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=training_image,      # XGBoost algorithm container\n",
    "    instance_type=\"ml.m5.xlarge\",  # type of training instance\n",
    "    instance_count=1,              # number of instances to be used\n",
    "    role=sm_role,                # IAM role to be used\n",
    "    max_run=20*60,                 # Maximum allowed active runtime\n",
    "    use_spot_instances=True,       # Use spot instances to reduce cost\n",
    "    max_wait=30*60,                # Maximum clock time (including spot delays)\n",
    ")\n",
    "\n",
    "# scale_pos_weight is a paramater that controls the relative weights of the classes.\n",
    "# Because the data set is so highly skewed, we set this parameter according to the ratio (n/y)\n",
    "scale_pos_weight = np.count_nonzero(df[target_label].values==0) / np.count_nonzero(df[target_label].values)\n",
    "\n",
    "# define its hyperparameters\n",
    "estimator.set_hyperparameters(\n",
    "    num_round=150,     # int: [1,300]\n",
    "    max_depth=5,     # int: [1,10]\n",
    "    alpha=2,         # float: [0,5]\n",
    "    eta=0.5,           # float: [0,1]\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric= \"auc,accuracy\",\n",
    "    scale_pos_weight=scale_pos_weight,  # set the balance between the 2 classes\n",
    ")\n",
    "\n",
    "# start a training (fitting) job\n",
    "estimator.fit({ \"train\": s3_input_train, \"validation\": s3_input_validation })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we've trained the xgboost algorithm on our data, deploying the model (hosting it behind a real-time endpoint) is just one function call!\n",
    "\n",
    "This deployment might take **up to 10 minutes**, and by default the code will wait for the deployment to complete.\n",
    "\n",
    "If you like, you can instead:\n",
    "\n",
    "- Un-comment the `wait=False` parameter\n",
    "- Use the [Endpoints page of the SageMaker Console](https://console.aws.amazon.com/sagemaker/home?#/endpoints) to check the status of the deployment\n",
    "- Skip over the *Evaluation* section below (which won't run until the deployment is complete), and start the Hyperparameter Optimization job - which will take a while to run too, so can be started in parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time endpoint:\n",
    "model_name='xgboost-model-'+datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "predictor = estimator.deploy(\n",
    "    model_name=model_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    # wait=False,  # Remember, predictor.predict() won't work until deployment finishes!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Since SageMaker is a general purpose ML platform and our endpoint is a web service, we'll need to be explicit that we're sending in tabular data (_serialized_ in CSV string format for the HTTPS request) and expect a tabular response (to be _deserialized_ from CSV to numpy).\n",
    "\n",
    "In the SageMaker SDK (from v2), this packing and unpacking of the payload for the web endpoint is handled by [serializer classes](https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html) and [deserializer classes](https://sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html).\n",
    "\n",
    "Unfortunately the pre-built `CSVDeserializer` produces nested Python lists of strings, rather than a numpy array of numbers - so rather than bothering to implement a custom class (like the examples [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/deserializers.py)) we'll be lazy and take this as a post-processing step.\n",
    "\n",
    "With this setup ready, requesting inferences is as easy as calling `predictor.predict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(output_path_test+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.CSVDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_numpy = test_df.drop([target_label], axis=1).values\n",
    "\n",
    "predictions = np.array(predictor.predict(X_test_numpy), dtype=float).squeeze()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.concat(\n",
    "    [\n",
    "        pd.Series(predictions, name=\"y_pred\", index=test_df.index),\n",
    "        test_df,\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "test_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plotting.generate_classification_report(\n",
    "    y_real=test_results[target_label],\n",
    "    y_predict_proba=test_results[\"y_pred\"],\n",
    "    decision_threshold=0.5,\n",
    "    class_names_list=[\"good\", \"default\"],\n",
    "    title=\"Initial risk model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hyperparameter Optimization (HPO)\n",
    "*Note, with the default settings below, the hyperparameter tuning job can take up to ~20 minutes to complete.*\n",
    "\n",
    "We will use SageMaker HyperParameter Optimization (HPO) to automate the searching process effectively. Specifically, we **specify a range**, or a list of possible values in the case of categorical hyperparameters, for each of the hyperparameter that we plan to tune.\n",
    "\n",
    "SageMaker hyperparameter tuning will automatically launch **multiple training jobs** with different hyperparameter settings, evaluate results of those training jobs based on a predefined \"objective metric\", and select the hyperparameter settings for future attempts based on previous results. For each hyperparameter tuning job, we will specify the maximum number of HPO tries (`max_jobs`) and how many of these can happen in parallel (`max_parallel_jobs`).\n",
    "\n",
    "Tip: `max_parallel_jobs` creates a **trade-off between performance and speed** (better hyperparameter values vs how long it takes to find these values). If `max_parallel_jobs` is large, then HPO is faster, but the discovered values may not be optimal. Smaller `max_parallel_jobs` will increase the chance of finding optimal values, but HPO will take more time to finish.\n",
    "\n",
    "Next we'll specify the objective metric that we'd like to tune and its definition, which includes the regular expression (Regex) needed to extract that metric from the CloudWatch logs of the training job. Since we are using built-in XGBoost algorithm here, it emits two predefined metrics: **validation:auc** and **train:auc**, and we elected to monitor *validation:auc* as you can see below. In this case (because it's pre-built for us), we only need to specify the metric name.\n",
    "\n",
    "For more information on the documentation of the Sagemaker HPO please refer [here](https://sagemaker.readthedocs.io/en/stable/tuner.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required HPO objects\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# set up hyperparameter ranges\n",
    "ranges = {\n",
    "    \"num_round\": IntegerParameter(1, 300),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 5),\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "}\n",
    "\n",
    "# set up the objective metric\n",
    "objective = 'validation:auc'\n",
    "\n",
    "# instantiate a HPO object\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=estimator,              # the SageMaker estimator object\n",
    "    hyperparameter_ranges=ranges,     # the range of hyperparameters\n",
    "    max_jobs=20,                      # total number of HPO jobs\n",
    "    max_parallel_jobs=4,              # how many HPO jobs can run in parallel\n",
    "    strategy=\"Bayesian\",              # the internal optimization strategy of HPO\n",
    "    objective_metric_name=objective,  # the objective metric to be used for HPO\n",
    "    objective_type=\"Maximize\",        # maximize or minimize the objective metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch HPO\n",
    "Now we can launch a hyperparameter tuning job by calling *fit()* function. After the hyperparameter tuning job is created, we can go to SageMaker console to track the progress of the hyperparameter tuning job until it is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start HPO\n",
    "tuner.fit({ \"train\": s3_input_train, \"validation\": s3_input_validation })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPO jobs often take quite a long time to finish and as such, sometimes you may want to free up the notebook and then resume the wait later.\n",
    "\n",
    "Just like the Estimator, we won't be able to `deploy()` the model until the HPO tuning job is complete; and the status is visible through both the [AWS Console](https://console.aws.amazon.com/sagemaker/home?#/hyper-tuning-jobs) and the [SageMaker API](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeHyperParameterTuningJob.html). We could for example write a polling script like the below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy and test optimized model\n",
    "Deploying the best model is another simple `.deploy()` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the best model from HPO\n",
    "model_name='xgboost-hpo-model-'+datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "hpo_predictor = tuner.deploy(\n",
    "    model_name=model_name\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once deployed, we can now evaluate the performance of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the predicted probabilities of the best model\n",
    "hpo_predictions = np.array(hpo_predictor.predict(X_test_numpy), dtype=float).squeeze()\n",
    "print(hpo_predictions)\n",
    "\n",
    "util.plotting.generate_classification_report(\n",
    "    y_real=test_results[target_label],\n",
    "    y_predict_proba=hpo_predictions,\n",
    "    decision_threshold=0.5,\n",
    "    class_names_list=[\"good\", \"default\"],\n",
    "    title=\"HPO risk model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker import clarify\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(role=sm_role,\n",
    "                                                      instance_count=1,\n",
    "                                                      instance_type='ml.m5.xlarge',\n",
    "                                                      sagemaker_session=sm_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = clarify.SHAPConfig(baseline=[test_df.iloc[0,1:].values.tolist()],\n",
    "                                 num_samples=15,\n",
    "                                 agg_method='mean_abs',\n",
    "                                 save_local_shap_values=False)\n",
    "\n",
    "explainability_output_path = 's3://{}/{}/clarify-explainability'.format(bucket_name, bucket_prefix)\n",
    "explainability_data_config = clarify.DataConfig(s3_data_input_path=output_path_train,\n",
    "                                s3_output_path=explainability_output_path,\n",
    "                                label=target_label,\n",
    "                                headers=df.columns.to_list(),\n",
    "                                dataset_type='text/csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = clarify.ModelConfig(model_name=model_name,\n",
    "                                   instance_type='ml.m5.xlarge',\n",
    "                                   instance_count=1,\n",
    "                                   accept_type='text/csv',\n",
    "                                   content_type='text/csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor.run_explainability(data_config=explainability_data_config,\n",
    "                                     model_config=model_config,\n",
    "                                     explainability_config=shap_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
